### Selector

> 논블록킹의 설계를 보면 이전 블로킹의 단점들을 해결할 수 있다.
>
> 

![Netty 핵심 컴포넌트](https://happygrammer.github.io/java/netty/selector.png)

##### **java.nio.channels.selector** 클래스가 논블로킹 입출력 구현의 핵심 역할을 한다.

언제든지 읽기나 쓰기 작업의 완료 상태를 확인할 수 있어 한 스레드로 여러 동시 연결을 처리할 수 있다.

- 적은 수의 쓰레드로 많은 연결을 처리할 수 있으므로 컨텍스트 전환에 따른 오버헤드 감소
- 입출력을 처리하지 않을 때는 스레드를 다른 작업에 활용할 수 있다.



#### Channel

> 하나 이상의 입출력 작업을 수행할 수 있는 하드웨어 장치, 파일, 네트워크 소켓, 프로그램 컴포넌트와 같은 엔티티에 대한 열린 연결



#### Callback

> 다른 메서드로 자신에 대한 참조를 제공할 수 있는 메서드



#### Future

> 작업이 완료되면 애플리케이션에 알리는 한 방법



> ### 네티의 비동기 프로그래밍 모델은 **<u>Future</u>**, **<u>콜백</u>**의 개념, 그리고 **<u>이벤트를 핸들러 메서드로 발송하는 작업</u>**을 기반으로 작동한다.



#### ChannelPipeline

> ChannelHandler 체인을 위한 컨테이너를 제공하며, 체인 상에서 인바운드와 아웃바운드 이벤트를 전파하는 API를 정의한다.
>
> channel이 생성되면 여기에 자동으로 자체적인 ChannelPipeline이 할당된다.
>
> - ChannelInitializer 구현은 ServerBootstrap에 등록된다.
> - ChannelInitializer.initChannel()이 호출되면 ChannelInitializer의 커스텀 집합을 파이프라인에 설치한다.
> - ChannelInitializer는 ChannelPipeline에서 자신을 제거한다.
>
> 



ChannelHandler를 ChannelPipeline에 추가할 때 ChannelHandler 및 ChannelPipeline 간의 바인딩을 나타내는

**ChannelHandlerContext** 하나가 할당된다. 이 객체는 기본 Channel을 가져오는 데 이용할 수 있지만 실제로는 아웃바운드 데이터를 기록할 때 주로 사용한다.



- 메시지를 보낼 때
  - Channel에 직접 기록하면, ChannelPipeline의 뒤쪽에서 시작되며,
  - ChannelHandlerContext에 기록하면, ChannelPipeline의 다음 Handler에서 시작된다.





##### 인바운드 데이터의 경우 Channel에서 읽는 각 메시지에 대해 호출되는 channelRead 를 재정의한다.

##### 이 메서드는 디코더의 decode() 메서드를 호출한 후 디코딩된 바이트를 파이프라인의 다음 ChannelInboundHandler로 전달한다.

##### 아웃바운드 메시지를 위한 패턴은 반대이며 인코더가 메시지를 바이트로 변환한 후 다음 ChannelOutboundHandler로 전달한다.

<hr/>



#### ByteBuf 사용 패턴

#### Heap 버퍼

> <u>JVM의 힙 공간에 데이터를 저장</u>한다. 
>
> <u>풀링이 사용되지 않는 경우</u> **빠른 할당**과 **해제 속도**를 보여준다.
>
> 



#### Direct 버퍼

> 다이렉트 버퍼는 네트워크 데이터 전송에 이상적임
>
> ##### 단점 : 힙 기반 버퍼보다 할당과 해제의 비용 부담이 약간 더 크다는 것
>
> 



#### CompositeByteBuf

> ByteBuffer 헤더와 ByteBuf 본문을 모두 포함하고 있다.
>
> 



### Heap vs Direct

`1. 다이렉트 버퍼가 메모리 비용 부담이 더 크다`

2. Heap 버퍼의 경우, 풀링을 하지 않을 때 빠른 할당과 속도를 낼 수 있다.

   

<hr/>

### 바이트 수준 작업 

- #### **capacity()**

> 바이트를 더 추가할 수 있는 공간 (기록할 수 있는 바이트)
>
> ByteBuf 배열 공간의 크기는 **[ 0 ~ capacity() - 1 ]** 로 구성된다.
>
> 

```java
ByteBuf buffer = ...;
for (int i = 0; i < buffer.capacity(); i++) {
  byte b = buffer.getByte(i);
  System.out.println((char)b);
}
```



- #### discardReadBytes()

> 폐기할 수 있는 바이트로 표시된 세그먼트는 이미 읽은 바이트를 포함한다.
>
> **discardReadBytes()**를 호출하면 **<u>이미 읽은 공간을 회수</u>**할 수 있다.
>
> 



- #### readBytes(ByteBuf dest)

> readerIndex의 기본값은 0이며, 읽은 바이트 수만큼 readerIndex를 증가시킨다.
>
> 

```java
// 읽을 수 있는 바이트를 모두 읽는다
while(buffer.isReadable()) {
  System.out.println(buffer.readByte());
}
```



- #### writeBytes(ByteBuf dest)

> writerIndex의 기본값은 0이며, 현재 writerIndex 위치부터 데이터를 기록하고 기록한 바이트 수만큼 writerIndex를 증가시킨다.
>
> 

```java
// 버퍼의 기록할 수 있는 바이트를 임의의 정수로 채운다.
ByteBuf buffer = ...;
while(buffer.writableBytes() >= 4) {
	buffer.writeInt(random.nextInt());
}
```





#### markReaderIndex(), markWriterIndex()

> ByteBuf의 readerIndex와 writerIndex를 지정한 값으로 표시하거나 해당 위치로 재설정한다.
>
> 



#### resetReaderIndex(), resetWriterIndex()

> ByteBuf의 readerIndex와 writerIndex를 재설정한다.





**clear()를 호출하면 readerIndex와 writerIndex를 모두 0으로 설정할 수 있다. 다만, 메모리의 내용은 지워지지 않는다.**

**Clear()는 메모리를 복사하지 않고 인덱스만 재설정하므로 discardReadBytes()에 비해 <u>실행 비용이 훨씬 낮다.</u>**





#### ByteBufAllocator 인터페이스

> 네티는 메모리 할당과 해제 시 발생하는 오버헤드를 줄이기 위해 ByteBufAllocator 인터페이스를 통해 지금까지 알아본 모든 종류의 ByteBuf 인스턴스를 할당하는 데 이용할 수 있는 풀링을 구현한다.
>
> ByteBufAllocator의 참조는 **Channel**에서 얻거나 **Channelhandler** 에 바인딩된 **ChannelHandlerContext** 를 통해 얻을 수 있다.
>
> 





##### 네티는 ByteBufAllocator의 두 가지 구현 방법을 제공한다. (PooledByteBufAllocator, UnpooledByteBufAllocator)

- **PooledByteBufAllocator**
  - 인스턴스를 풀링해 성능을 개선하고 메모리 단편화를 최소화하며, jemalloc 이라는 고효율 메모리 할당 방식을 이용
- **UnpooledByteBufAllocator**
  - 인스턴스를 풀링하지 않고 호출될 때마다 새로운 인스턴를 반환한다.





#### 참조 카운팅

> 다른 객체에서 더 이상 참조하지 않는 객체가 보유한 리소스를 해제해 메모리 사용량과 성능을 최적화하는 기법
>
> 
>
> ReferenceCounted 구현 인스턴스는 일반적으로 활성 참조 카운트 1을 가지고 시작하며, 참조 카운트가 1 이상이면 객체가 해제되지 않지만, 0으로 감소하면 인스턴스가 해제된다.
>
> 
>
> 참조카운팅은 PooledByteBufAllocator와 같은 풀링 구현에서 메모리 할당의 오버헤드를 줄이는 데 반드시 필요하다.
>
> 

















